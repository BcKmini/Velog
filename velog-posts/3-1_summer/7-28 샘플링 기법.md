<h2 id="📝목차">📝목차</h2>
<h3 id="샘플링-기법--over-sampling-class-imbalanced-problem--해결방법">샘플링 기법 – Over Sampling Class Imbalanced Problem – 해결방법</h3>
<ul>
<li>Resampling
<span style="color: indianred;">Under sampling</span>: 다수 데이터 줄이기
<span style="color: indianred;">Over sampling</span>: 소수 데이터 부풀리기
Hybrid resampling: Over + Under sampling <h2 id="📌span-stylecolorslateblue샘플링-기법--under-samplingspan">📌<span style="color: slateblue;">샘플링 기법 – Under Sampling</span></h2>
Random Under Sampling
Majority 데이터를 랜덤하게 추출해서 줄이는 방법
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/e397910b-4361-4dbd-9178-415d0a9bf909/image.png" /></li>
</ul>
<p>대표적인 방법: Random Under Sampling, <span style="color: indianred;">Tomek Links</span> (가장 많이 활용), EasyEnsemble 등</p>
<h2 id="📌span-stylecolorslateblue샘플링-기법--under-sampling-span">📌<span style="color: slateblue;">샘플링 기법 – Under Sampling </span></h2>
<h2 id="span-stylecolorolivedrab1-random-under-samplingspan"><span style="color: olivedrab;">1. Random Under Sampling</span></h2>
<ul>
<li>Majority 데이터에서 Random하게 데이터를 선택하여 제거 가장 단순한 방법</li>
<li>단점: Cluster, Borderline 특성을 고려하지 못함</li>
</ul>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/689368a5-a949-43bf-ac4b-fe117df8d6cb/image.png" /></p>
<h2 id="span-stylecolorolivedrab2-tomek-linksspan"><span style="color: olivedrab;">2. Tomek Links</span></h2>
<ul>
<li>Tomek links는 서로 다른 클래스에 속하는 한 쌍의 데이터</li>
<li>가까운 한 쌍의 데이터를 찾은 다음 그 중에서 다수 클래스(majority class)에 속하는 데이터를 제거하는 방법</li>
<li>다수 클래스를 제거함으로써 데이터 불균형 문제 해결 -&gt; 분류 문제를 조금 더 수월하게 만들어 줌</li>
<li>여전히 데이터 손실에 대한 문제를 가지고 있음
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/0a135c79-f0ba-42fe-8f10-2bd2f686fbca/image.png" /></li>
<li>Majority 데이터와 Minority의 Borderline에 있는 Majority 데이터를 제거</li>
<li>단점: 단순차원(2차원 혹은 3차원)은 가능, 4차원 이상 데이터는 거리 및 Link 해석이 난해해짐</li>
</ul>
<h2 id="span-stylecolorolivedrab-3-easyensemblespan"><span style="color: olivedrab;"> 3. EasyEnsemble</span></h2>
<ul>
<li>Majority 데이터와 Minority 데이터를 동일 수만큼 랜덤 추출</li>
<li>Random 추출된 데이터를 학습</li>
<li>위 과정을 n번 반복
(서로 다른 머신러닝을 동시에 돌려 예측결과에 대해 많이 나온 예측값으로 결과를 냄)</li>
<li>ℎ_(𝑖,𝑗) (𝑥) is signum function (sign 함수)<p align="center">
<img src="https://velog.velcdn.com/images/mi_nini/post/e0d66f56-9d90-43ac-a2fd-73bcf4d62bca/image.png" />
</p> </li>
<li>𝐻𝑖(𝑥) is output of 𝑖−𝑡ℎ sub-problem
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/9a6a761e-6c99-4e5d-b64c-5b05af17bf5a/image.png" /></li>
</ul>
<h2 id="📌span-stylecolorslateblue샘플링-기법--random-over-samplingspan">📌<span style="color: slateblue;">샘플링 기법 – Random Over Sampling</span></h2>
<ul>
<li>소수의 데이터를 random 하게 sampling 한 이후 기존 데이터와 합치는 방법</li>
<li>가장 단순한 방법, 의뢰로 작동이 잘 될 때도 많음
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/cab67d30-2a8a-4c2d-81b5-bf3ca792a420/image.png" /></li>
</ul>
<h2 id="📌span-stylecolorslateblue샘플링-기법--over-samplingspan">📌<span style="color: slateblue;">샘플링 기법 – Over Sampling</span></h2>
<h3 id="span-stylecolorolivedrab1--smote-synthetic-minority-over-sampling-techniquespan"><span style="color: olivedrab;">1.  SMOTE (Synthetic Minority Over-sampling Technique)</span></h3>
<ul>
<li>Over sampling의 가장 기본적 기법 (널리 사용됨)</li>
<li>소수의 데이터에 KNN을 적용한 이후, 샘플과 이웃 사이의 중간에 랜덤하게 생성</li>
<li>다양한 변형 기법들이 존재
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/02048af4-494b-4683-8fa3-569aade477a4/image.png" /><h2 id="span-stylecolorolivedrab2-blsmote-borderline-smotespan"><span style="color: olivedrab;">2. BLSMOTE (Borderline SMOTE)</span></h2>
</li>
<li>다른 class와의 경계(borderline)에 있는 샘플들을 늘림으로써 분류하기 더 어려운 부분에 집중</li>
<li>Minority 데이터의 이웃 데이터 중 절반 이상이 Major 데이터라면 Borderline이라고 판단</li>
<li>Borderline에 대하여 SMOTE 수행
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/48a62222-bf1f-4aee-b5f9-f10a5a35ed85/image.png" />
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/49a1541c-1643-41e6-a96b-8169e43daac7/image.png" /></li>
</ul>
<h2 id="span-stylecolorolivedrab3-dbsmotespan"><span style="color: olivedrab;">3. DBSMOTE</span></h2>
<ul>
<li>DBSMOTE (DBSCAN SMOTE)</li>
<li>Minority 데이터에 DBSCAN 적용  클러스터 생성</li>
<li>각 클러스터의 중점과 데이터 사이의 연결선 상에서 랜덤하게 데이터 생성</li>
<li>장점: Noise를 제거 하면서 샘플링 가능 (DBSCAN 클러스터링의 장점)
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/59fb5fd4-ab2f-4167-b71d-648ff38be465/image.png" /></li>
</ul>
<h2 id="📌hybrid-resampling">📌Hybrid Resampling</h2>
<h3 id="class-imbalanced-problem--해결방법">Class Imbalanced Problem – 해결방법</h3>
<ul>
<li>Resampling</li>
<li>Over sampling: 소수 데이터 부풀리기</li>
<li>Under sampling: 다수 데이터 줄이기</li>
<li><span style="color: indianred;">Hybrid resampling: Over + Under sampling</span> </li>
</ul>
<h2 id="span-stylecolorolivedrabhybrid-resamplingspan"><span style="color: olivedrab;">Hybrid Resampling</span></h2>
<ul>
<li>Over Sampling과 Under Sampling을 결합하는 방법<h3 id="smote--tomek-links를-결합하여-사용">SMOTE + Tomek Links를 결합하여 사용</h3>
</li>
<li>SMOTE: Minority 데이터를 Over Sampling 수행</li>
<li>Tomek Links: Majority 데이터를 Under Sampling 수행
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/10844a7a-b766-4764-bcc1-e7a45a026958/image.png" /></li>
</ul>
<h3 id="smote--ipf">SMOTE + IPF</h3>
<ul>
<li>SMOTE의 경우 Outlier (Noise)와 불명확한 Borderline이 존재할 경우 성능 저하</li>
<li>Iterative Partitioning Filter (IPF)를 적용하여 SMOTE에 결합</li>
</ul>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/e7d55609-4598-459c-b1b9-c009c5197bf7/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/a62af245-68d3-48d7-be8c-e5b77214daa7/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td>## 📌<span style="color: slateblue;">SMOTE 실습</span></td>
<td></td>
</tr>
</tbody></table>
<hr />
<h2 id="코드-참고--">코드 참고 -&gt;</h2>
<p><a href="https://github.com/KYoungMIn-code/KYoungMIn-code">https://github.com/KYoungMIn-code/KYoungMIn-code</a></p>

<hr />
<hr />
<h2 id="📌span-stylecolorslateblue모형적합성--실험설계의-이해span">📌<span style="color: slateblue;">모형적합성 &amp; 실험설계의 이해!</span></h2>
<h2 id="span-stylecolorolivedrab1-모형의-적합성span"><span style="color: olivedrab;">1. 모형의 적합성</span></h2>
<h3 id="모델이-단순하면">모델이 단순하면</h3>
<ul>
<li>항상 높은 MSE</li>
<li>편파적 판단을 일삼는 모델</li>
<li>기출문제도, 실전문제도 못 푼다.</li>
</ul>
<h3 id="모델이-너무-복잡하면">모델이 너무 복잡하면</h3>
<p>학습데이터 MSE 감소</p>
<ul>
<li>검증데이터 MSE 증가</li>
<li>기출문제는 잘 풀지만 실전에 약함</li>
</ul>
<h3 id="모델의-복잡도에-따른-trade-off-존재">모델의 복잡도에 따른 Trade-off 존재</h3>
<ul>
<li>그렇다면 어떻게 해결??</li>
<li>어떻게 적합한 모델을 만들지?</li>
</ul>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/278c2aa3-7bcb-4a3d-af91-bb0b6c5a4d76/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/aad94fdd-6b1b-4af6-959e-54a0da2d4c72/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td>## <span style="color: olivedrab;">2. 데이터 분할을 통한 적합성 확보</span></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/1d943454-108f-4784-ba7b-b7fca9393e41/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/d52ae2f7-8004-4a6c-b293-65b2a41585ad/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td>모델 적합성? 데이터 분할?</td>
<td></td>
</tr>
<tr>
<td>시험공부를 생각하면 쉽다</td>
<td></td>
</tr>
<tr>
<td>- Training: 기출문제</td>
<td></td>
</tr>
<tr>
<td>- Validation: 모의고사</td>
<td></td>
</tr>
<tr>
<td>- Testing: 수능시험</td>
<td></td>
</tr>
</tbody></table>
<p>모델 적합성? 데이터 분할?
시험공부를 생각하면 쉽다</p>
<ul>
<li>Training: 모형 f 추정</li>
<li>Validation: 모형 f가 적합한지 검증 </li>
<li>Testing: 최종 선택 모형의 성능평가</li>
</ul>
<hr />
<h2 id="데이터-분할을-통한-적합성-확보--대표성-무작위성">데이터 분할을 통한 적합성 확보 – 대표성, 무작위성</h2>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/6b3d0d3b-4cba-46fa-a8e5-fa851009ee68/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/9d8ecb2b-6f6a-41da-bfc8-b37f959ed9d8/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td>- Validation set은</td>
<td></td>
</tr>
<tr>
<td>- Training set에서 분할 사용</td>
<td></td>
</tr>
<tr>
<td>---</td>
<td></td>
</tr>
<tr>
<td># 학습</td>
<td></td>
</tr>
</tbody></table>
<p>Train Set을 이용하여 다양한 머신러닝 모델을 돌려본다. </p>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/de596a1e-297d-422b-b323-faaa0a84fd13/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/59e83a0d-533c-460a-9971-65a557918085/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td>___</td>
<td></td>
</tr>
<tr>
<td># 검증</td>
<td></td>
</tr>
</tbody></table>
<p>Validation Set을 이용하여 성능이 여전히 유효한지 검증한다.
가장 좋은 모형을 선택한다.</p>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/f9e7b95e-2bbd-4f84-94a2-2a9d286f65bd/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/cfc29e00-ea8d-418c-aced-4f8a79284e0d/image.png" /></th>
</tr>
</thead>
</table>
<hr />
<h1 id="테스트">테스트</h1>
<p>Test Set을 이용하여 최종 성능을 산출한다.</p>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/24f5d007-509e-4e6a-b874-78d3aaa77ba5/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/44dbc9ed-7997-4183-8090-ffe8d038669e/image.png" /></th>
</tr>
</thead>
</table>
<hr />
<h1 id="📌전처리">📌전처리</h1>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/edd153f4-2998-436f-9bb7-8ee221ce28e3/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/f97485e1-c4b0-49eb-934a-f5ed03d0473d/image.png" /></th>
</tr>
</thead>
<tbody><tr>
<td><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/fa40624c-2527-41bd-93c9-d9d6455d9702/image.png" /></td>
<td></td>
</tr>
<tr>
<td>&gt; 참고할 만한 사이트:</td>
<td></td>
</tr>
<tr>
<td>- Concept Hierarchy Generation:  <a href="https://www.sciencedirect.com/topics/computer-science/concept-hierarchy">https://www.sciencedirect.com/topics/computer-science/concept-hierarchy</a> =</td>
<td></td>
</tr>
<tr>
<td>- data Cube: <a href="https://www.javatpoint.com/data-warehouse-what-is-data-cube">https://www.javatpoint.com/data-warehouse-what-is-data-cube</a></td>
<td></td>
</tr>
<tr>
<td>- Numerosity / Dimensionality Reduction: <a href="https://greenjun.github.io/data%20mining/Data-Reduction/">https://greenjun.github.io/data%20mining/Data-Reduction/</a></td>
<td></td>
</tr>
<tr>
<td><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/07d9ab10-b6cc-4bc9-b836-5eaf551257e7/image.png" /></td>
<td></td>
</tr>
</tbody></table>
<h2 id="📌span-stylecolorslateblue과적합-overfittingspan">📌<span style="color: slateblue;">과적합 (Overfitting)</span></h2>
<ul>
<li>모형이 복잡할수록, 데이터가 작을 수록 쉽게 발생</li>
<li>과적합은 인공지능(AI) 및 데이터 사이언스(Data Science) 분야에서 아직까지 완벽히 해결되지 않은 이슈</li>
</ul>
<table>
<thead>
<tr>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/40535c67-03ef-4286-b372-76ef0a389740/image.png" /></th>
<th><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/480839b2-9de3-4ed0-921a-c690d97a7471/image.png" /></th>
</tr>
</thead>
</table>
<h3 id="우리가-선택한-모형의-결과">우리가 선택한 모형의 결과</h3>
<ul>
<li>1번: 사실상 불가능한 모델 </li>
<li>2번: 편파성은 낮고 분산이 높음</li>
<li>3번: 편파성이 높고 분산이 낮음</li>
<li>4번: 둘 다 높음 (쓰레기 모형)</li>
</ul>
<h3 id="2번과-3번-중에-선택해야-하는데-">2번과 3번 중에 선택해야 하는데 ,</h3>
<ul>
<li>적절한 모형 선택과 실험 설계를 통한 과적합을 방지해야 하는데…</li>
<li>대부분 2번을 선택해서 과적합을 최대한 줄이는 방법을 선택</li>
<li>대표적으로 앙상블 모델이 2번에 해당된다.
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/ff4fdb2b-6a38-456c-b111-67023bddef5d/image.png" /></li>
</ul>