<h1 id="📌-과제2---시각지능-yolo">📌 과제2 - 시각지능 YOLO</h1>
<hr />
<h2 id="chapter-2-object-detection">Chapter 2. Object Detection</h2>
<blockquote>
<p>Object Detection 예시
자율 주행 : <a href="https://youtu.be/ahOdb7CCg2A">https://youtu.be/ahOdb7CCg2A</a> 
<a href="https://youtu.be/KdYz77p6NfM">https://youtu.be/KdYz77p6NfM</a>
스포츠 : <a href="https://youtu.be/GrAdG9r7shU">https://youtu.be/GrAdG9r7shU</a> 
의료 : <a href="https://youtu.be/k1RycrhK36Q">https://youtu.be/k1RycrhK36Q</a> 
군사 : <a href="https://youtu.be/2kSeaAlbj3w">https://youtu.be/2kSeaAlbj3w</a>
<a href="https://youtu.be/Lf-4tWqH3t8">https://youtu.be/Lf-4tWqH3t8</a></p>
</blockquote>
<h3 id="object-detection">Object Detection?</h3>
<p>Classiﬁcation + Localization
Multi-Labeled Classiﬁcation + Bounding Box Regression</p>
<h3 id="object-detection-주요-개념">Object Detection 주요 개념</h3>
<ol>
<li>Bounding Box</li>
<li>Class Classiﬁcation</li>
<li>Conﬁdence Score</li>
<li>IoU</li>
<li>NMS</li>
<li>Precision, Recall, AP, mAP</li>
<li>Annotation</li>
</ol>
<hr />
<h2 id="bounding-box">bounding box</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/896b191c-c0fe-460a-afa7-074b03296238/image.png" /></p>
<ul>
<li>하나의 Object가 포함된 최소 크기 박스
(x min, y min, x max, y max 
x center, y center, width, height)
즉, 위치 정보</li>
</ul>
<hr />
<h2 id="conﬁdencescore">ConﬁdenceScore</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/804f935a-501a-4cfa-94e8-0a66b58f4d39/image.png" /></p>
<blockquote>
<p>Ground-Truth Bounding Box의 
Conﬁdence Score = 1</p>
</blockquote>
<p>Predicted Bounding Box의 
Conﬁdence Score가 1에 가까울수록
Object가 있다고 판단!</p>
<ul>
<li>모델에 따라 계산이 조금씩 다름</li>
</ul>
<ol>
<li>단순히 Object가 있을 확률</li>
<li>Object가 있을 확률 X IoU</li>
<li>Object가 특정 클래스일 확률 X IoU</li>
</ol>
<hr />
<h2 id="iou-intersection-over-union">IoU (Intersection over Union)</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/7da95e87-79fb-4994-bd95-2ac1682082d8/image.png" /></p>
<p>Ground-truth Bounding Box 
Prediction Bounding Box
두 박스의 중복 영역 크기를 통해 측정 
-&gt; 겹치는 영역이 넓을수록 좋은 예측</p>
<ul>
<li>0 ~ 1 사이의 값 
값이 클수록 좋은 예측</li>
</ul>
<hr />
<h2 id="nms-non-maximum-suppression">NMS (Non-Maximum Suppression)</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/5120ba87-6514-4b43-a5cb-5d76a3a1b73b/image.png" /></p>
<p>동일 Object에 대한 중복 박스 제거</p>
<ul>
<li>1.일정 Conﬁdence Score 이하의 
Bounding Box 제거</li>
<li><ol start="2">
<li>남은 Bounding Box들을
Conﬁdence Score 내림차순으로 정렬</li>
</ol>
</li>
<li><ol start="3">
<li>첫 Bounding Box(Conﬁdence 
Score가 가장 높은!)와의 IoU 값이 
일정 이상인 박스들을 제거</li>
</ol>
</li>
<li><ol start="4">
<li>Bounding Box가 하나 될 때까지 반복</li>
</ol>
</li>
</ul>
<blockquote>
<ul>
<li>IoU가 일정 값 이상이면
같은 Object를 가리키는 것이라고 판단,
상대적으로 Conﬁdence Score가 
낮은 Bounding Box를 제거하는 것</li>
</ul>
</blockquote>
<ul>
<li>Conﬁdence Score Threshold가 높을수록,
IoU Threshold가 낮을수록,
박스에 대한 중복 판단이 깐깐해지는 것</li>
<li>Conﬁdence Score Threshold
IoU Threshold
사용자가 조절할 수 있다. 
즉, HyperParameter</li>
</ul>
<hr />
<h2 id="precision-recall-ap-map">Precision, Recall, AP, mAP</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/4fc507be-8425-4caf-b11b-7043bac83c7a/image.png" /></p>
<h3 id="confusion-matrix-with-od">Confusion Matrix with O.D</h3>
<ul>
<li>TP : 실제 Object를 모델이 Object라 예측 
  -&gt; 모델이 올바르게 탐지</li>
<li>FP : Object 아닌데 모델이 Object라 예측 
  -&gt; 모델의 잘못된 탐지</li>
<li>FN : 실제 Object를 모델이 아니라고 예측 
  -&gt; 모델의 잘못된 탐지</li>
<li>TN : Object 아닌데 모델도 아니라고 예측 
  -&gt; 모델이 탐지하지 않음</li>
</ul>
<blockquote>
<ul>
<li>Precision
: TP / (TP + FP)
: 모델이 Object라 예측한 것 중 
실제 Object의 비율</li>
</ul>
</blockquote>
<ul>
<li>Recall
: TP / (TP + FN)
: 실제 Object 중 모델이</li>
<li>예측하여 맞춘 Object의 비율 Confusion Matrix with O.D IoU Threshold 값에 따라 Precision, Recall 변화</li>
</ul>
<hr />
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/f414141a-6b11-4ffa-9764-1b16ccd3fadc/image.png" /></p>
<h3 id="iou-threshold-값에-따른-변화-1">IoU Threshold 값에 따른 변화 1</h3>
<p>강아지에 대한 Precision? 2/4
강아지에 대한 Recall? 2/4</p>
<ul>
<li><p>IoU Threshold 값에 따른 변화 2 </p>
</li>
<li><blockquote>
<p>IoU Threshold 값 올림 </p>
</blockquote>
</li>
<li><blockquote>
<p>Bounding Box 기준 깐깐
강아지에 대한 Precision? 2/2 
강아지에 대한 Recall? 2/4</p>
</blockquote>
</li>
<li><p>IoU Threshold 값에 따른 변화 3 </p>
</li>
<li><blockquote>
<p>IoU Threshold 값 내림 </p>
</blockquote>
</li>
<li><blockquote>
<p>Bounding Box 기준 느슨
강아지에 대한 Precision? 4/8 
강아지에 대한 Recall? 4/4</p>
</blockquote>
</li>
</ul>
<hr />
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/745b9f32-98a4-4c78-ac79-a05283e280f5/image.png" /></p>
<h3 id="precision---recall-curve-precision과-recall을-모두-감안한-지표">Precision - Recall Curve Precision과 Recall을 모두 감안한 지표</h3>
<p>Average Precision (AP) Precision - Recall Curve 그래프 아래의 면적</p>
<p>mean Average Precision (mAP) 각 클래스 별 AP를 합산하여 평균을 낸 것</p>
<h2 id="✔-annotation">✔ Annotation</h2>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/76f2654d-68dc-4156-aba9-ec38d8bb2839/image.png" /></p>
<ul>
<li>이미지내 Detection 정보를별도의설명파일로제공되는것을 Annotation이라고함. </li>
<li>Annotation은 Object의 Bounding Box 위치나 Object 이름등을특정포맷으로제공.</li>
</ul>
<hr />
<h1 id="📌3-ultralytics-yolo-v8">📌3. UltraLytics YOLO v8</h1>
<blockquote>
<h2 id="github8주차yolo"><a href="https://github.com/BcKmini/Ai_Python">GitHub</a>/8주차/Yolo</h2>
</blockquote>
<hr />
<h1 id="📌4-roboﬂow">📌4. Roboﬂow</h1>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/def383ef-b26f-4175-822e-198efdbffa87/image.png" /></p>
<blockquote>
<p>Computer Vision 
End-to-End 개발 가능</p>
</blockquote>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/4b4c128c-e305-406b-a54c-e56ce53803e8/image.png" /></p>
<blockquote>
<p>Roboﬂow : Universe
Universe
Datasets Hub</p>
</blockquote>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/fdc9aa0c-9d79-4acc-bf12-562fc165e46a/image.png" /></p>
<ul>
<li>names : 클래스별 이름</li>
<li>nc : 클래스의 수 </li>
<li>train : training set의 경로 
val : validation set의 경로 
test : test set의 경로 (옵션)
<img alt="" src="https://velog.velcdn.com/images/mi_nini/post/6617eff0-bc12-482d-9ba6-78dddc9117e8/image.png" /></li>
</ul>
<p>images / labels 폴더 내부에는 
동일한 이름의 이미지 파일과 
텍스트 파일이 저장되어 있다.
예시) train/images/1.jpg 
       train/labels/1.txt</p>
<p><img alt="" src="https://velog.velcdn.com/images/mi_nini/post/49827633-57a3-4acf-b095-dea9a0e5ad80/image.png" />
labels 폴더의 txt 파일에는
클래스 정보와 Normalize 된 x, y, w, h가 담겨있다.</p>
<hr />
<h2 id="💻roboﬂow--projects">💻Roboﬂow : Projects</h2>
<p>이미지를 직접 라벨링해보고 새로운 프로젝트를 할 예정</p>